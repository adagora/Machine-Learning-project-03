# -*- coding: utf-8 -*-
"""W3.Fraud_Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1m3jjEMRiziuG7rYfVOR3gx5aM0ZRRENR
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
import matplotlib.pyplot as plt
from sklearn.preprocessing import scale
import random
import seaborn as sns

df = pd.read_csv('creditcard.csv')
df.head()
print(df.describe())

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
sns.countplot(x='Class', data=df)

fraud = train_transaction.loc[df['Class'] == 1]
non_fraud = df.loc[df['Class'] == 0]
print(len(fraud))
print(len(non_fraud))

ax = fraud.plot.scatter(x='Amount', y='Class', color='Orange', label='Fraud')
non_fraud.plot.scatter(x='Amount', y='Class', color='Blue', label='Normal', ax=ax)
plt.show()

# chose column
features = ['Amount'] + ['V%d' % number for number in range(1, 29)]

# ours target, we want to predict
target = 'Class'

#create
X = df[features]
y = df[target]

def normalize(X):
    """
    Make the distribution of the values of each variable similar by subtracting the mean and by dividing by the standard deviation.
    """
    for feature in X.columns:
        X[feature] -= X[feature].mean()
        X[feature] /= X[feature].std()
    return X

# Define the model

model = LogisticRegression(C=1e5)

# Define the splitter for spliting data in train set and a test set
splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=0)

# Loop through the splits (only one)
for train_indices, test_indices in splitter.split(X, y):
  #Select the train and test data
  X_train, y_train = X.iloc[train_indices], y.iloc[train_indices]
  X_test, y_test =X.iloc[test_indices], y.iloc[test_indices]
  
  # Normalize the data
  X_train = normalize(X_train)
  X_test = normalize(X_test)
  
  # Fit & Predict
  model.fit(X_train, y_train)
  y_pred = model.predict(X_test)
  
  # Result
  print(classification_report(y_test, y_pred))

from sklearn.metrics import recall_score,accuracy_score
print(recall_score(y_test,y_pred,average=None))
print(accuracy_score(y_test,y_pred))

# algorithm is performing extremely well
# So our model is not doing a good job of recognising frauds, only .61% for 1. It means fraud

# Undersample the data. To improve the recall, let's implement undersampling. Here the code is trying to reduce the number of non fraudulent transactions equivalent to fraudulent ones.
no_frauds = len(df[df['Class'] == 1])
non_fraud_indices = df[df.Class == 0].index
random_indices = np.random.choice(non_fraud_indices,no_frauds, replace=False)
fraud_indices = df[df.Class == 1].index
under_sample_indices = np.concatenate([fraud_indices,random_indices])
under_sample = df.loc[under_sample_indices]

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
sns.countplot(x='Class', data=under_sample)

from sklearn.model_selection import train_test_split
X_under = under_sample.loc[:,under_sample.columns != 'Class']
y_under = under_sample.loc[:,under_sample.columns == 'Class']
X_under_train, X_under_test, y_under_train, y_under_test = train_test_split(X_under,y_under,test_size = 0.3, random_state = 0)

lr_under = LogisticRegression()
lr_under.fit(X_under_train,y_under_train)
y_under_pred = lr_under.predict(X_under_test)
print(recall_score(y_under_test,y_under_pred))
print(accuracy_score(y_under_test,y_under_pred))

lr_balanced = LogisticRegression(class_weight = 'balanced')
lr_balanced.fit(X_train,y_train)
y_balanced_pred = lr_balanced.predict(X_test)
print(recall_score(y_test,y_balanced_pred))
print(accuracy_score(y_test,y_balanced_pred))

#BALANCED#
# accuracy really good 98%
# recall score really good 90%

from sklearn.metrics import confusion_matrix

confusion_matrix_value = confusion_matrix(y_test,y_balanced_pred)
sns.set(font_scale=1.4)
confusion_matrix_value
#sns.heatmap(confusion_matrix_value, annot=True)

import pandas as pd

df_confusion = pd.crosstab(y_test, y_balanced_pred,  rownames=['Actual'], colnames=['Predicted'], margins=True)
df_confusion

